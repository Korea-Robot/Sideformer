import torch
import torch.nn.functional as F
import numpy as np
import torch.nn as nn
from PIL import Image
import os
import cv2
from transformers import (
    SegformerImageProcessor,
    SegformerForSemanticSegmentation,
    TrainingArguments,
    Trainer
)

import json
from torch.utils.data import Dataset, DataLoader
from torchvision import transforms
import matplotlib.pyplot as plt

# ===================================================================
# ì‚¬ìš©ìê»˜ì„œ ì œê³µí•´ì£¼ì‹  ì½”ë“œ (ìˆ˜ì • ì—†ì´ ê·¸ëŒ€ë¡œ ì‚¬ìš©)
# ===================================================================

class SurfaceSegmentationDataset(Dataset):
    """ì „ì²˜ë¦¬ëœ ì´ë¯¸ì§€/ë§ˆìŠ¤í¬ ê²½ë¡œë¥¼ ë°›ì•„ PyTorch í…ì„œë¡œ ë³€í™˜í•˜ëŠ” í´ë˜ìŠ¤"""
    def __init__(self, data_list: list, target_size: tuple, is_train: bool):
        self.data_list = data_list
        self.target_size = target_size
        self.is_train = is_train

        if self.is_train:
            self.image_transform = transforms.Compose([
                transforms.ToPILImage(),
                transforms.Resize(self.target_size),
                transforms.ColorJitter(brightness=0.1, contrast=0.1),
                transforms.ToTensor(),
            ])
        else:
            self.image_transform = transforms.Compose([
                transforms.ToPILImage(),
                transforms.Resize(self.target_size),
                transforms.ToTensor(),
            ])

        if self.is_train:
            self.mask_transform = transforms.Compose([
                transforms.ToPILImage(),
                transforms.Resize(self.target_size, interpolation=transforms.InterpolationMode.NEAREST),
                transforms.ToTensor()
            ])
        else:
            self.mask_transform = transforms.Compose([
                transforms.ToPILImage(),
                transforms.Resize(self.target_size, interpolation=transforms.InterpolationMode.NEAREST),
                transforms.ToTensor()
            ])

    def __len__(self) -> int:
        return len(self.data_list)

    def __getitem__(self, idx: int) -> dict:
        item = self.data_list[idx]
        image_path = item['image_path']
        mask_path = item['mask_path']

        image = cv2.imread(image_path)
        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
        mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)

        if self.is_train:
            seed = torch.randint(0, 2**32, (1,)).item()
            torch.manual_seed(seed)
            image = self.image_transform(image)
            torch.manual_seed(seed)
            mask = self.mask_transform(mask)
        else:
            image = self.image_transform(image)
            mask = self.mask_transform(mask)

        mask = mask.squeeze(0).long()
        return {'pixel_values': image, 'labels': mask}

# --- ì„¤ì • ---
metadata_path = "./processed_dataset/metadata.json"
batch_size = 32
target_size = (512, 512)
num_workers = 16 # í™˜ê²½ì— ë§ê²Œ ì¡°ì ˆí•˜ì„¸ìš”

# metadata.json ë¡œë“œ ë° ë°ì´í„° ë¡œë” ìƒì„±
with open(metadata_path, 'r', encoding='utf-8') as f:
    metadata = json.load(f)

valid_dataset = SurfaceSegmentationDataset(metadata['valid_data'], target_size, is_train=False)
valid_loader = DataLoader(valid_dataset, batch_size=batch_size, shuffle=True, num_workers=num_workers)


# ===================================================================
# ë°ì´í„° ì‹œê°í™” ë° ì €ì¥ ì½”ë“œ (ìˆ˜ì •ë¨)
# ===================================================================

ID_TO_COLOR = [
    [0, 0, 0],         # 0: background - Black
    [255, 0, 0],       # 1: class 1 - Red
    [0, 255, 0],       # 2: class 2 - Green
    [0, 0, 255],       # 3: class 3 - Blue
    [255, 255, 0],     # 4: class 4 - Yellow
]

def visualize_and_save_batch(images, masks, output_dir, num_to_show=10):
    """
    ë°ì´í„°ë¡œë”ì—ì„œ ê°€ì ¸ì˜¨ ë°°ì¹˜ë¥¼ ì‹œê°í™”í•˜ê³  íŒŒì¼ë¡œ ì €ì¥í•©ë‹ˆë‹¤.
    
    Args:
        images (torch.Tensor): ì´ë¯¸ì§€ í…ì„œ (B, C, H, W)
        masks (torch.Tensor): ë§ˆìŠ¤í¬ í…ì„œ (B, H, W)
        output_dir (str): ì‹œê°í™” ê²°ê³¼ë¥¼ ì €ì¥í•  ë””ë ‰í† ë¦¬ ê²½ë¡œ
        num_to_show (int): ì €ì¥í•  ìƒ˜í”Œì˜ ìµœëŒ€ ê°œìˆ˜
    """
    count = min(images.size(0), num_to_show)
    
    for i in range(count):
        # 1. í…ì„œë¥¼ NumPy ë°°ì—´ë¡œ ë³€í™˜
        image_np = (images[i].permute(1, 2, 0).numpy() * 255).astype(np.uint8)
        mask_np = masks[i].numpy().astype(np.uint8)

        # 2. ì»¬ëŸ¬ ë§ˆìŠ¤í¬ ìƒì„±
        mask_color = np.zeros((mask_np.shape[0], mask_np.shape[1], 3), dtype=np.uint8)
        for class_id, color in enumerate(ID_TO_COLOR):
            mask_color[mask_np == class_id] = color

        # 3. ì´ë¯¸ì§€ì™€ ë§ˆìŠ¤í¬ ì¤‘ì²©
        overlayed_image = cv2.addWeighted(image_np, 0.6, mask_color, 0.4, 0)
        
        # 4. Matplotlibìœ¼ë¡œ ì´ë¯¸ì§€ë“¤ í‘œì‹œ
        fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(18, 6))
        
        ax1.imshow(image_np)
        ax1.set_title(f'Original Image #{i+1}')
        ax1.axis('off')
        
        ax2.imshow(mask_color)
        ax2.set_title(f'Ground Truth Mask #{i+1}')
        ax2.axis('off')
        
        ax3.imshow(overlayed_image)
        ax3.set_title(f'Overlayed Image #{i+1}')
        ax3.axis('off')
        
        plt.tight_layout()
        
        # 5. ì´ë¯¸ì§€ íŒŒì¼ë¡œ ì €ì¥
        save_path = os.path.join(output_dir, f'result_sample_{i+1}.png')
        plt.savefig(save_path)
        plt.close(fig)  # ë©”ëª¨ë¦¬ ëˆ„ìˆ˜ ë°©ì§€ë¥¼ ìœ„í•´ ì°½ì„ ë‹«ì•„ì¤ë‹ˆë‹¤.
        
        print(f"âœ… ì‹œê°í™” ê²°ê³¼ ì €ì¥ ì™„ë£Œ: {save_path}")


# --- ì‹œê°í™” ë° ì €ì¥ ì‹¤í–‰ ---
if __name__ == '__main__':
    # ê²°ê³¼ë¥¼ ì €ì¥í•  ë””ë ‰í† ë¦¬ ì„¤ì •
    output_directory = "visualization_results"
    
    # ë””ë ‰í† ë¦¬ê°€ ì—†ìœ¼ë©´ ìƒì„±
    if not os.path.exists(output_directory):
        os.makedirs(output_directory)
        print(f"ğŸ“‚ '{output_directory}' ë””ë ‰í† ë¦¬ë¥¼ ìƒì„±í–ˆìŠµë‹ˆë‹¤.")

    # ë°ì´í„° ë¡œë”ì—ì„œ í•œ ë°°ì¹˜ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤.
    data_iter = iter(valid_loader)
    batch = next(data_iter)
    
    pixel_values = batch['pixel_values']
    labels = batch['labels']
    
    # ê°€ì ¸ì˜¨ ë°°ì¹˜ì—ì„œ 10ê°œì˜ ìƒ˜í”Œì„ ì‹œê°í™”í•˜ê³  ì €ì¥í•©ë‹ˆë‹¤.
    print(f"\nğŸš€ ë°ì´í„°ì…‹ì—ì„œ {min(10, batch_size)}ê°œì˜ ìƒ˜í”Œì„ ì‹œê°í™”í•˜ê³  ì €ì¥í•©ë‹ˆë‹¤...")
    visualize_and_save_batch(
        pixel_values, 
        labels, 
        output_dir=output_directory, 
        num_to_show=10
    )