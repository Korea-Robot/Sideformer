import os
import json
from pathlib import Path
from typing import List, Dict, Tuple

import cv2
import numpy as np
import torch
from torch.utils.data import Dataset, DataLoader
from torchvision import transforms

class PolygonSegmentationDataset(Dataset):
    """
    í´ë¦¬ê³¤ ë¶„í•  ë°ì´í„°ë¥¼ ë¡œë“œí•˜ê³  ë³€í™˜í•˜ëŠ” PyTorch Dataset í´ë˜ìŠ¤.

    Args:
        root_dir (str): 'Polygon_0001', 'Polygon_0002' ë“±ì´ í¬í•¨ëœ ìµœìƒìœ„ ë””ë ‰í† ë¦¬ ê²½ë¡œ.
        is_train (bool): Trueì´ë©´ í•™ìŠµìš© ë°ì´í„° ì¦ê°•ì„ ì ìš©í•˜ê³ , Falseì´ë©´ ê²€ì¦ìš© ë³€í™˜ì„ ì ìš©í•©ë‹ˆë‹¤.
        target_size (Tuple[int, int]): ì´ë¯¸ì§€ë¥¼ ë¦¬ì‚¬ì´ì¦ˆí•  ëª©í‘œ í¬ê¸°.
    """
    def __init__(self, root_dir: str, is_train: bool, target_size: Tuple[int, int] = (512, 512)):
        self.root_path = Path(root_dir)
        self.is_train = is_train
        self.target_size = target_size

        # ë°ì´í„° íŒŒì¼ ìŒ (ì´ë¯¸ì§€, ë§ˆìŠ¤í¬)ì„ ì°¾ìŠµë‹ˆë‹¤.
        self.data_pairs = self._get_data_pairs()
        if not self.data_pairs:
            raise IOError(f"'{root_dir}' ë””ë ‰í† ë¦¬ì—ì„œ ìœ íš¨í•œ ì´ë¯¸ì§€/ë§ˆìŠ¤í¬ ìŒì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

        # --- ì´ë¯¸ì§€ ë³€í™˜ íŒŒì´í”„ë¼ì¸ ---
        # í•™ìŠµ ì‹œì—ëŠ” ë°ì´í„° ì¦ê°•(augmentation)ì„ ì ìš©í•©ë‹ˆë‹¤.
        if self.is_train:
            self.image_transform = transforms.Compose([
                transforms.ToPILImage(),
                transforms.Resize(self.target_size),
                # transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.1),
                transforms.RandomApply([
                    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.1)
                ], p=0.5),
                # transforms.RandomHorizontalFlip(p=0.5),
                transforms.ToTensor(),
                transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
            ])
        # ê²€ì¦ ì‹œì—ëŠ” ë°ì´í„° ì¦ê°•ì„ ì ìš©í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.
        else:
            self.image_transform = transforms.Compose([
                transforms.ToPILImage(),
                transforms.Resize(self.target_size),
                transforms.ToTensor(),
                transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
            ])

        # --- ë§ˆìŠ¤í¬ ë³€í™˜ íŒŒì´í”„ë¼ì¸ ---
        # ë§ˆìŠ¤í¬ëŠ” í”½ì…€ê°’ì´ í´ë˜ìŠ¤ IDì´ë¯€ë¡œ ë³´ê°„ë²•ìœ¼ë¡œ NEARESTë¥¼ ì‚¬ìš©í•´ì•¼ í•©ë‹ˆë‹¤.
        if self.is_train:
            self.mask_transform = transforms.Compose([
                transforms.ToPILImage(),
                # transforms.Resize(self.target_size, interpolation=transforms.InterpolationMode.NEAREST),
                # transforms.RandomHorizontalFlip(p=0.5),
                transforms.ToTensor()
            ])
        else:
            self.mask_transform = transforms.Compose([
                transforms.ToPILImage(),
                transforms.Resize(self.target_size),
                transforms.ToTensor()
            ])

    def _get_data_pairs(self) -> List[Dict[str, Path]]:
        """root_dirë¥¼ íƒìƒ‰í•˜ì—¬ ëª¨ë“  (ì´ë¯¸ì§€, ë§ˆìŠ¤í¬) íŒŒì¼ ìŒì„ ì°¾ìŠµë‹ˆë‹¤."""
        data_pairs = []
        for poly_dir in self.root_path.iterdir():
            # 'Polygon_XXXX' í˜•íƒœì˜ ë””ë ‰í† ë¦¬ì¸ì§€ í™•ì¸
            if poly_dir.is_dir() and poly_dir.name.startswith('Polygon_'):
                mask_dir = poly_dir / 'mask'
                if not mask_dir.exists():
                    continue

                # ë””ë ‰í† ë¦¬ ë‚´ì˜ ëª¨ë“  jpg ì´ë¯¸ì§€ ê²€ìƒ‰
                for image_path in poly_dir.glob('*.jpg'):
                    # í•´ë‹¹ ì´ë¯¸ì§€ì— ëŒ€í•œ ë§ˆìŠ¤í¬ íŒŒì¼ ê²½ë¡œ ìƒì„±
                    mask_filename = f"{image_path.stem}_mask.png"
                    mask_path = mask_dir / mask_filename

                    # ì´ë¯¸ì§€ì™€ ë§ˆìŠ¤í¬ íŒŒì¼ì´ ëª¨ë‘ ì¡´ì¬í•  ê²½ìš°ì—ë§Œ ë¦¬ìŠ¤íŠ¸ì— ì¶”ê°€
                    if mask_path.exists():
                        data_pairs.append({'image': image_path, 'mask': mask_path})
        return data_pairs

    def __len__(self) -> int:
        """ë°ì´í„°ì…‹ì˜ ì´ ìƒ˜í”Œ ìˆ˜ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤."""
        return len(self.data_pairs)

    def __getitem__(self, idx: int) -> Dict[str, torch.Tensor]:
        """ì§€ì •ëœ ì¸ë±ìŠ¤(idx)ì˜ ë°ì´í„° ìƒ˜í”Œ(ì´ë¯¸ì§€, ë§ˆìŠ¤í¬)ì„ ë¡œë“œí•˜ê³  ë³€í™˜í•˜ì—¬ ë°˜í™˜í•©ë‹ˆë‹¤."""
        item = self.data_pairs[idx]

        # ì´ë¯¸ì§€ ë¡œë“œ (OpenCV: BGR -> RGBë¡œ ë³€í™˜)
        image = cv2.imread(str(item['image']))
        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)

        # ë§ˆìŠ¤í¬ ë¡œë“œ (ë‹¨ì¼ ì±„ë„, ê·¸ë ˆì´ìŠ¤ì¼€ì¼)
        # mask = cv2.imread(str(item['mask']), cv2.IMREAD_GRAYSCALE)
        mask = cv2.imread(str(item['mask']), cv2.IMREAD_UNCHANGED)


        mask = cv2.resize(mask, self.target_size, interpolation=cv2.INTER_NEAREST)
        mask = torch.from_numpy(mask).long()  # (H, W)

        # í•™ìŠµ ì‹œ, ì´ë¯¸ì§€ì™€ ë§ˆìŠ¤í¬ì— ë™ì¼í•œ ëœë¤ ë³€í™˜(ì˜ˆ: ì¢Œìš° ë°˜ì „)ì„ ì ìš©
        if self.is_train:
            seed = torch.seed() # ë™ì¼í•œ ë³€í™˜ì„ ìœ„í•œ ì‹œë“œ ìƒì„±
            torch.manual_seed(seed)
            image = self.image_transform(image)
            torch.manual_seed(seed)
            # mask = self.mask_transform(mask)
        else:
            image = self.image_transform(image)
            # mask = self.mask_transform(mask)

        # ë§ˆìŠ¤í¬ í…ì„œì˜ ì°¨ì›ì„ (1, H, W) -> (H, W)ë¡œ ë³€ê²½í•˜ê³ ,
        # ì†ì‹¤ ê³„ì‚°ì„ ìœ„í•´ Long íƒ€ì…ìœ¼ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.

        # mask = mask.squeeze(0).long()
        # mask=mask.squeeze(0)

        return {
            'pixel_values': image,
            'labels': mask
        }

if __name__ == '__main__':
    # --- ë°ì´í„°ì…‹ ì‚¬ìš© ì˜ˆì œ ---
    
    # 1. ì„¤ì •
    ROOT_DIRECTORY = '~/data/indo_walking/polygon_segmentation'
    ROOT_DIRECTORY = "/home/work/data/indo_walking/polygon_segmentation"
    CLASS_MAPPING_FILE = os.path.join(ROOT_DIRECTORY, 'class_mapping.json')
    BATCH_SIZE = 4
    
    # 2. í´ë˜ìŠ¤ ì •ë³´ ë¡œë“œ (ì‹œê°í™” ë“±ì— ì‚¬ìš© ê°€ëŠ¥)
    try:
        with open(CLASS_MAPPING_FILE, 'r') as f:
            class_info = json.load(f)
        print(f"âœ… ì´ {len(class_info)}ê°œì˜ í´ë˜ìŠ¤ ì •ë³´ë¥¼ ë¡œë“œí–ˆìŠµë‹ˆë‹¤.")
    except FileNotFoundError:
        print(f"ğŸš¨ í´ë˜ìŠ¤ ë§¤í•‘ íŒŒì¼('{CLASS_MAPPING_FILE}')ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        class_info = None

    # 3. í•™ìŠµìš© ë°ì´í„°ì…‹ ë° ë°ì´í„°ë¡œë” ìƒì„±
    train_dataset = PolygonSegmentationDataset(root_dir=ROOT_DIRECTORY, is_train=True)
    train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=4)
    
    # 4. ê²€ì¦ìš© ë°ì´í„°ì…‹ ë° ë°ì´í„°ë¡œë” ìƒì„±
    valid_dataset = PolygonSegmentationDataset(root_dir=ROOT_DIRECTORY, is_train=False)
    valid_loader = DataLoader(valid_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=4)

    print(f"\n- ì´ ë°ì´í„° ìƒ˜í”Œ ìˆ˜: {len(train_dataset)}")
    print(f"- í•™ìŠµìš© ë°°ì¹˜ ìˆ˜: {len(train_loader)}")
    print(f"- ê²€ì¦ìš© ë°°ì¹˜ ìˆ˜: {len(valid_loader)}")
    
    # 5. ë°ì´í„°ë¡œë”ì—ì„œ í•œ ë°°ì¹˜ë¥¼ ê°€ì ¸ì™€ì„œ í™•ì¸
    if len(train_loader) > 0:
        batch = next(iter(train_loader))
        images = batch['pixel_values']
        masks = batch['labels']
        
        print("\n--- ë°ì´í„° ë°°ì¹˜ í™•ì¸ ---")
        print(f"ì´ë¯¸ì§€ í…ì„œ ëª¨ì–‘ (Batch, Channels, Height, Width): {images.shape}")
        print(f"ë§ˆìŠ¤í¬ í…ì„œ ëª¨ì–‘ (Batch, Height, Width): {masks.shape}")
        print(f"ì´ë¯¸ì§€ í…ì„œ íƒ€ì…: {images.dtype}")
        print(f"ë§ˆìŠ¤í¬ í…ì„œ íƒ€ì…: {masks.dtype}")
        print(f"í•œ ë°°ì¹˜ ë‚´ ë§ˆìŠ¤í¬ í´ë˜ìŠ¤ ID ë¶„í¬: {torch.unique(masks)}")

        breakpoint()